import torch
import torch.nn as nn
from torchvision import models, transforms
from torch.utils.tensorboard import SummaryWriter
import os
import matplotlib.pyplot as plt
import numpy as np
import cv2
import random

# å¼•å…¥ä½ çš„æ•°æ®åŠ è½½æ¨¡å—
from dataloader import *

# ====================================================
# [æ”¹è¿›] è‡ªå®šä¹‰æ¨¡å‹ç»“æ„: FaceResNet
# ====================================================


class FaceResNet(nn.Module):
    def __init__(self, num_classes=2):
        super(FaceResNet, self).__init__()
        # 1. ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ (Transfer Learning)
        # æ³¨æ„ï¼šPyTorch 1.8 ä½¿ç”¨ pretrained=True
        self.backbone = models.resnet18(pretrained=True)

        # 2. è·å– backbone çš„è¾“å‡ºç‰¹å¾ç»´åº¦ (ResNet18 æ˜¯ 512)
        in_features = self.backbone.fc.in_features

        # ç§»é™¤åŸæœ‰çš„å…¨è¿æ¥å±‚ï¼Œä¸ºäº†æ–¹ä¾¿åç»­æå–ç‰¹å¾ï¼Œæˆ‘ä»¬åªä¿ç•™å·ç§¯éƒ¨åˆ†ä½œä¸º backbone
        # è¿™é‡Œçš„ trick æ˜¯æŠŠ backbone çš„ fc æ›¿æ¢æˆ Identity (ä¸åšä»»ä½•å¤„ç†)ï¼Œæˆ–è€…åœ¨ forward é‡Œé‡å†™
        self.backbone.fc = nn.Identity()

        # 3. [ç»“æ„æ”¹è¿›] é‡æ„åˆ†ç±»å¤´ (Classifier Head)
        # å¢åŠ  Dropout é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå¢åŠ ä¸­é—´å±‚æå‡è¡¨è¾¾èƒ½åŠ›
        self.classifier = nn.Sequential(
            nn.Linear(in_features, 256),      # å¢åŠ ä¸€ä¸ªéšè—å±‚ 512 -> 256
            nn.ReLU(),
            nn.Dropout(p=0.5),                # [å…³é”®] ä¸¢å¼ƒ 50% ç¥ç»å…ƒï¼Œå¼ºåŠ›æŠ—è¿‡æ‹Ÿåˆ
            nn.Linear(256, num_classes)       # æœ€ç»ˆè¾“å‡º 256 -> 2
        )

    def forward(self, x):
        # å…ˆç»è¿‡å·ç§¯å±‚æå–ç‰¹å¾
        features = self.backbone(x)
        # å†ç»è¿‡è‡ªå®šä¹‰çš„åˆ†ç±»å¤´
        out = self.classifier(features)
        return out

# ====================================================
# å¯è§†åŒ–å·¥å…·ç±» (é€‚é…æ–°æ¨¡å‹ç»“æ„)
# ====================================================


class FeatureMapVisualizer:
    def __init__(self, model, target_layer):
        self.model = model
        self.feature_maps = []
        target_layer.register_forward_hook(self.hook_fn)

    def hook_fn(self, module, input, output):
        self.feature_maps.append(output.detach())

    def visualize(self, input_tensor, save_name: str = None):
        self.feature_maps = []
        # æ³¨æ„ï¼šè¿™é‡Œåªè·‘ backbone ä¹Ÿå¯ä»¥ï¼Œæˆ–è€…è·‘å…¨æ¨¡å‹
        _ = self.model(input_tensor)
        if not self.feature_maps:
            return

        fmap = self.feature_maps[0].cpu().squeeze(0)
        num_channels = min(16, fmap.shape[0])

        fig, axes = plt.subplots(4, 4, figsize=(10, 10))
        fig.suptitle(f"Layer Feature Maps (Top {num_channels})", fontsize=15)

        for i in range(num_channels):
            ax = axes[i // 4, i % 4]
            img = fmap[i].numpy()
            img = (img - img.min()) / (img.max() - img.min() + 1e-9)
            ax.imshow(img, cmap='viridis')
            ax.axis('off')
        if save_name is not None:
            plt.savefig(save_name, bbox_inches="tight")
        plt.show()


class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.gradients = None
        self.activations = None
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_full_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        self.activations = output

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def generate(self, input_tensor, class_idx=None):
        output = self.model(input_tensor)
        if class_idx is None:
            class_idx = output.argmax(dim=1).item()
        self.model.zero_grad()
        output[0, class_idx].backward()

        gradients = self.gradients
        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])
        activations = self.activations.detach()
        for i in range(activations.shape[1]):
            activations[:, i, :, :] *= pooled_gradients[i]

        heatmap = torch.mean(activations, dim=1).squeeze()
        heatmap = np.maximum(heatmap.cpu().numpy(), 0)
        heatmap /= (np.max(heatmap) + 1e-9)
        return heatmap, class_idx


def show_cam_result(raw_img_pil, heatmap, pred_label: str = "", true_label: str = "", save_path: str = None):
    raw_img_pil = raw_img_pil.resize((256, 256))
    heatmap = cv2.resize(heatmap, (256, 256))
    heatmap_uint8 = np.uint8(255 * heatmap)
    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
    heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB)

    superimposed = heatmap_color * 0.4 + np.array(raw_img_pil) * 0.6
    superimposed = np.clip(superimposed, 0, 255).astype(np.uint8)

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 3, 1)
    plt.imshow(raw_img_pil)
    plt.title(f"True: {true_label}")
    plt.axis('off')
    plt.subplot(1, 3, 2)
    plt.imshow(heatmap_color)
    plt.title("Attention Heatmap")
    plt.axis('off')
    plt.subplot(1, 3, 3)
    plt.imshow(superimposed)
    plt.title(f"Pred: {pred_label}")
    plt.axis('off')
    plt.suptitle(
        "Improved Model Analysis (with Dropout & Pretrained)", fontsize=15)
    if save_path is not None:
        plt.savefig(save_path, bbox_inches="tight")
    plt.show()


# ====================================================
# 1. åˆå§‹åŒ–é…ç½®
# ====================================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("device:", device)
writer = SummaryWriter('runs/resnet18_improved_experiment')

# [æ”¹è¿›] åˆå§‹åŒ–æˆ‘ä»¬è‡ªå®šä¹‰çš„æ”¹è¿›ç‰ˆæ¨¡å‹
model = FaceResNet(num_classes=2).to(device)

criterion = nn.CrossEntropyLoss()
# [æ”¹è¿›] é™ä½å­¦ä¹ ç‡ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨äº†é¢„è®­ç»ƒæƒé‡ï¼Œä¸éœ€è¦é‚£ä¹ˆå¤§çš„æ­¥å­
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)
# [æ”¹è¿›] å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼šæ¯ 5 ä¸ª epoch å­¦ä¹ ç‡ä¹˜ä»¥ 0.1
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

# ====================================================
# 2. è®­ç»ƒä¸è¯„ä¼°å‡½æ•°
# ====================================================


def train_one_epoch(model, loader, optimizer, criterion, device, epoch_index):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for i, (imgs, labels) in enumerate(loader):
        imgs = imgs.to(device)
        labels = labels.to(device).long()

        outputs = model(imgs)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * imgs.size(0)
        preds = outputs.argmax(dim=1)
        correct += (preds == labels).sum().item()
        total += imgs.size(0)

        if i % 10 == 0:
            global_step = (epoch_index - 1) * len(loader) + i
            writer.add_scalar('Loss/train_step', loss.item(), global_step)

    return running_loss / total, correct / total


@torch.no_grad()
def evaluate(model, loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    for imgs, labels in loader:
        imgs = imgs.to(device)
        labels = labels.to(device).long()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        running_loss += loss.item() * imgs.size(0)
        preds = outputs.argmax(dim=1)
        correct += (preds == labels).sum().item()
        total += imgs.size(0)
    return running_loss / total, correct / total


# ====================================================
# 3. ä¸»å¾ªç¯
# ====================================================
num_epochs = 2  # ç”±äºæœ‰é¢„è®­ç»ƒï¼Œé€šå¸¸éœ€è¦çš„ epoch æ›´å°‘
best_val_acc = 0.0
save_path = "best_improved_resnet18.pth"

# è®°å½• loss / acc ç”¨äºç”»æ›²çº¿
train_losses = []
val_losses = []
train_accs = []
val_accs = []

print(f"Start Training Improved Model...")

for epoch in range(1, num_epochs + 1):
    train_loss, train_acc = train_one_epoch(
        model, train_loader, optimizer, criterion, device, epoch)
    val_loss,   val_acc = evaluate(model, valid_loader, criterion, device)

    # [æ–°å¢] æ›´æ–°å­¦ä¹ ç‡
    scheduler.step()
    current_lr = optimizer.param_groups[0]['lr']

    print(f"Epoch [{epoch}/{num_epochs}] LR={current_lr:.1e} "
          f"Train Loss={train_loss:.4f} Acc={train_acc:.4f} | "
          f"Val Loss={val_loss:.4f} Acc={val_acc:.4f}")

    writer.add_scalar('Loss/train_epoch', train_loss, epoch)
    writer.add_scalar('Accuracy/train_epoch', train_acc, epoch)
    writer.add_scalar('Loss/val_epoch', val_loss, epoch)
    writer.add_scalar('Accuracy/val_epoch', val_acc, epoch)

    # ä¿å­˜åˆ°åˆ—è¡¨ï¼Œåé¢ç”»æ›²çº¿
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs.append(train_acc)
    val_accs.append(val_acc)

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), save_path)
        print(f"  >>> Best model updated! Val Acc: {best_val_acc:.4f}")

writer.close()
print("\nâœ… Training Finished!")

# è®­ç»ƒå®Œæˆåç”» loss æ›²çº¿å¹¶ä¿å­˜
epochs_list = range(1, num_epochs + 1)
plt.figure(figsize=(8, 6))
plt.plot(epochs_list, train_losses, label="Train Loss")
plt.plot(epochs_list, val_losses, label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training and Validation Loss")
plt.legend()
plt.grid(True)
plt.savefig("train_loss_curve.png", bbox_inches="tight")
plt.close()

# è®­ç»ƒå®Œæˆåç”» acc æ›²çº¿å¹¶ä¿å­˜
plt.figure(figsize=(8, 6))
plt.plot(epochs_list, train_accs, label="Train Acc")
plt.plot(epochs_list, val_accs, label="Val Acc")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Training and Validation Accuracy")
plt.legend()
plt.grid(True)
plt.savefig("train_acc_curve.png", bbox_inches="tight")
plt.close()

# ====================================================
# 4. å¯è§†åŒ–åˆ†æ
# ====================================================
print("\nğŸ¨ Loading best model for Visualization...")
model.load_state_dict(torch.load(save_path, map_location=device))
model.eval()

try:
    idx = random.randint(0, len(valid_dataset)-1)
    print(f"ğŸ” Analyzing Image Index: {idx}")
    img_tensor, label_idx = valid_dataset[idx]

    # å‡†å¤‡æ•°æ®
    inv_tensor = img_tensor * 0.5 + 0.5
    inv_tensor = torch.clamp(inv_tensor, 0, 1)
    raw_img_pil = transforms.ToPILImage()(inv_tensor)
    input_tensor = img_tensor.unsqueeze(0).to(device)
    class_names = {0: 'Fake', 1: 'Real'}

    # 1. ç‰¹å¾å›¾ (æŸ¥çœ‹ layer1)
    # æ³¨æ„ï¼šå› ä¸ºæˆ‘ä»¬å°† resnet å°è£…åœ¨ self.backbone é‡Œï¼Œæ‰€ä»¥è®¿é—®è·¯å¾„å˜äº†
    viz_feat = FeatureMapVisualizer(model, model.backbone.layer1)
    viz_feat.visualize(input_tensor, save_name="train_feature_maps.png")

    # 2. Grad-CAM (æŸ¥çœ‹ layer4)
    # åŒæ ·ï¼Œè·¯å¾„å˜ä¸º model.backbone.layer4
    grad_cam = GradCAM(model, model.backbone.layer4)
    heatmap, pred_idx = grad_cam.generate(input_tensor)

    show_cam_result(
        raw_img_pil,
        heatmap,
        pred_label=class_names.get(pred_idx, str(pred_idx)),
        true_label=class_names.get(label_idx, str(label_idx)),
        save_path="train_gradcam.png",
    )

except Exception as e:
    print(f"âŒ Visualization Failed: {e}")
